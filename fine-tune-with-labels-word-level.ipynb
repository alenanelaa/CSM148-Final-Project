{"metadata":{"colab":{"machine_shape":"hm","provenance":[],"gpuType":"T4"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7046357,"sourceType":"datasetVersion","datasetId":4054750},{"sourceId":7046404,"sourceType":"datasetVersion","datasetId":4054779},{"sourceId":7124613,"sourceType":"datasetVersion","datasetId":4109840},{"sourceId":7127117,"sourceType":"datasetVersion","datasetId":4111505}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"192cf98614b947ddb300aed1713c99c3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa96074662a74ce1999beb82a206bcd1","IPY_MODEL_e076289f9eed4a73a4afc47f866ed5a3","IPY_MODEL_14899f30cfd84403aca8ca65055e5da5"],"layout":"IPY_MODEL_242561560ba643b7b5f3a805afee7db7"}},"fa96074662a74ce1999beb82a206bcd1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18707f9dc9524e199ff85991b3b45a75","placeholder":"​","style":"IPY_MODEL_cd927e5de72748059c596b4e2700c305","value":"tokenizer_config.json: 100%"}},"e076289f9eed4a73a4afc47f866ed5a3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f814c25819749b5b7f51cf35872126c","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_960f42baf0be4a4fa41d58e779200778","value":28}},"14899f30cfd84403aca8ca65055e5da5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bdd317e7819a492d840a9274385d45f0","placeholder":"​","style":"IPY_MODEL_cf73b21208a342ceb0c832b6e6ad216b","value":" 28.0/28.0 [00:00&lt;00:00, 1.83kB/s]"}},"242561560ba643b7b5f3a805afee7db7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18707f9dc9524e199ff85991b3b45a75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd927e5de72748059c596b4e2700c305":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f814c25819749b5b7f51cf35872126c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"960f42baf0be4a4fa41d58e779200778":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bdd317e7819a492d840a9274385d45f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf73b21208a342ceb0c832b6e6ad216b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1a61731795a45a5ba9abcb55c10ce06":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f36777b915604f7aa90fe33141e94151","IPY_MODEL_f5315731f5a94605972031a14aaa90c8","IPY_MODEL_6a4b64978592418a9b80128df4726c72"],"layout":"IPY_MODEL_dded268e6419421c8fe1f843cd369a02"}},"f36777b915604f7aa90fe33141e94151":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b81d234df42f4601af36e49c6e63f8f3","placeholder":"​","style":"IPY_MODEL_9c74670497ed4ab789b106a6bc3459de","value":"config.json: 100%"}},"f5315731f5a94605972031a14aaa90c8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_13a1a063a22d41019eb06a8f303311bd","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_596ed04503f64d84b8c60cd999b81ca1","value":570}},"6a4b64978592418a9b80128df4726c72":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53c34b061ea3492586b1165e646fd719","placeholder":"​","style":"IPY_MODEL_51b985326bb44516bda2107622cb8ac2","value":" 570/570 [00:00&lt;00:00, 44.5kB/s]"}},"dded268e6419421c8fe1f843cd369a02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b81d234df42f4601af36e49c6e63f8f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c74670497ed4ab789b106a6bc3459de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13a1a063a22d41019eb06a8f303311bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"596ed04503f64d84b8c60cd999b81ca1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53c34b061ea3492586b1165e646fd719":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51b985326bb44516bda2107622cb8ac2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f02efc235475495c8455bc923e3ab175":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9fe40ac97ba541c0806cc7a00a15ad1a","IPY_MODEL_9672fcf9315c4b3f8fb33c33fbf82caf","IPY_MODEL_4747906d31e6495ab63098be94f4a6f7"],"layout":"IPY_MODEL_09e463e92782444f992fbe2cce498927"}},"9fe40ac97ba541c0806cc7a00a15ad1a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12ae2bfb9baf45c5b7491620384f9c0d","placeholder":"​","style":"IPY_MODEL_6bb9dc2818e146449913925e75fa98b2","value":"vocab.txt: 100%"}},"9672fcf9315c4b3f8fb33c33fbf82caf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7357d1ca1a9b4bb9b13cc4b8efd86569","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0c57be2429f04aebbfff7799a37811de","value":231508}},"4747906d31e6495ab63098be94f4a6f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2efe681068d74a7282047d3627bce733","placeholder":"​","style":"IPY_MODEL_5054bac6f4f2480e8a555fe486a4057f","value":" 232k/232k [00:00&lt;00:00, 2.70MB/s]"}},"09e463e92782444f992fbe2cce498927":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12ae2bfb9baf45c5b7491620384f9c0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bb9dc2818e146449913925e75fa98b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7357d1ca1a9b4bb9b13cc4b8efd86569":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c57be2429f04aebbfff7799a37811de":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2efe681068d74a7282047d3627bce733":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5054bac6f4f2480e8a555fe486a4057f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6542f29a65b4268bf0e7552b856f346":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e60d39d814ec41158c862e846ec29cd3","IPY_MODEL_bf8831ce2f1a459d8c64e976f420d5fc","IPY_MODEL_90f76600a3404f958db458676c732348"],"layout":"IPY_MODEL_fde85d764cd54fab9bca578030625c9e"}},"e60d39d814ec41158c862e846ec29cd3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52d265a4203e4bfb96040c5cd3ad73fc","placeholder":"​","style":"IPY_MODEL_f84309405e314c3db82b19327e68996e","value":"tokenizer.json: 100%"}},"bf8831ce2f1a459d8c64e976f420d5fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb10754a7e3d49dd95fc6d7b87c14ffb","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_95ad897eb7034200bc59999c6d3b2e96","value":466062}},"90f76600a3404f958db458676c732348":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ca24af665f341ce99ae760bdc3734b2","placeholder":"​","style":"IPY_MODEL_3d014e8acb4c41dcb734f12d81b0d532","value":" 466k/466k [00:00&lt;00:00, 11.2MB/s]"}},"fde85d764cd54fab9bca578030625c9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52d265a4203e4bfb96040c5cd3ad73fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f84309405e314c3db82b19327e68996e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb10754a7e3d49dd95fc6d7b87c14ffb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95ad897eb7034200bc59999c6d3b2e96":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ca24af665f341ce99ae760bdc3734b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d014e8acb4c41dcb734f12d81b0d532":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install comet_ml\nimport comet_ml\nfrom comet_ml import Experiment\nfrom comet_ml.integration.pytorch import log_model\n!pip install lightning\nimport lightning\nfrom lightning.fabric import Fabric\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\nimport re\nimport os\nimport lzma\nfrom tqdm import tqdm\nimport mmap\nimport random\nimport matplotlib.pyplot as plt\nimport numpy as np","metadata":{"id":"MLgQvdLzeOnA","outputId":"7046651c-3201-4c51-eeb1-bc347662020f","execution":{"iopub.status.busy":"2023-12-05T07:54:16.015616Z","iopub.execute_input":"2023-12-05T07:54:16.016735Z","iopub.status.idle":"2023-12-05T07:54:41.664972Z","shell.execute_reply.started":"2023-12-05T07:54:16.016702Z","shell.execute_reply":"2023-12-05T07:54:41.663912Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: comet_ml in /opt/conda/lib/python3.10/site-packages (3.35.3)\nRequirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from comet_ml) (4.19.0)\nRequirement already satisfied: psutil>=5.6.3 in /opt/conda/lib/python3.10/site-packages (from comet_ml) (5.9.3)\nRequirement already satisfied: python-box<7.0.0 in /opt/conda/lib/python3.10/site-packages (from comet_ml) (6.1.0)\nRequirement already satisfied: requests-toolbelt>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from comet_ml) (0.10.1)\nRequirement already satisfied: requests>=2.18.4 in /opt/conda/lib/python3.10/site-packages (from comet_ml) (2.31.0)\nRequirement already satisfied: semantic-version>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from comet_ml) (2.10.0)\nRequirement already satisfied: sentry-sdk>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from comet_ml) (1.34.0)\nRequirement already satisfied: simplejson in /opt/conda/lib/python3.10/site-packages (from comet_ml) (3.19.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from comet_ml) (1.16.0)\nRequirement already satisfied: urllib3>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from comet_ml) (1.26.15)\nRequirement already satisfied: websocket-client<1.4.0,>=0.55.0 in /opt/conda/lib/python3.10/site-packages (from comet_ml) (1.3.3)\nRequirement already satisfied: wrapt>=1.11.2 in /opt/conda/lib/python3.10/site-packages (from comet_ml) (1.15.0)\nRequirement already satisfied: wurlitzer>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from comet_ml) (3.0.3)\nRequirement already satisfied: everett[ini]<3.2.0,>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from comet_ml) (3.1.0)\nRequirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /opt/conda/lib/python3.10/site-packages (from comet_ml) (0.21.6)\nRequirement already satisfied: rich>=13.3.2 in /opt/conda/lib/python3.10/site-packages (from comet_ml) (13.5.2)\nRequirement already satisfied: configobj in /opt/conda/lib/python3.10/site-packages (from everett[ini]<3.2.0,>=1.0.1->comet_ml) (5.0.8)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (23.1.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (2023.7.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.30.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.9.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.18.4->comet_ml) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.18.4->comet_ml) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.18.4->comet_ml) (2023.7.22)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=13.3.2->comet_ml) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=13.3.2->comet_ml) (2.16.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet_ml) (0.1.0)\nRequirement already satisfied: lightning in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning) (6.0.1)\nRequirement already satisfied: fsspec[http]<2025.0,>2021.06.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2023.10.0)\nRequirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.9.0)\nRequirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.24.3)\nRequirement already satisfied: packaging<25.0,>=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\nRequirement already satisfied: torch<4.0,>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.0.0)\nRequirement already satisfied: torchmetrics<3.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.2.0)\nRequirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.66.1)\nRequirement already satisfied: typing-extensions<6.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.5.0)\nRequirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning) (2.1.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (2.31.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (3.8.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=20.0->lightning) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.12.0->lightning) (3.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.12.0->lightning) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.12.0->lightning) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.12.0->lightning) (3.1.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<4.0,>=1.12.0->lightning) (2.1.3)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=1.12.0->lightning) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"fabric = Fabric(precision=\"16-mixed\")\ndevice = fabric.device","metadata":{"id":"zapMzAIA1agp","outputId":"2a67e3bf-f168-4843-a94c-c5ffa8304817","execution":{"iopub.status.busy":"2023-12-05T07:54:41.666922Z","iopub.execute_input":"2023-12-05T07:54:41.667252Z","iopub.status.idle":"2023-12-05T07:54:41.934925Z","shell.execute_reply.started":"2023-12-05T07:54:41.667226Z","shell.execute_reply":"2023-12-05T07:54:41.934121Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"INFO: Using 16-bit Automatic Mixed Precision (AMP)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Loading Jokes dataset","metadata":{"id":"tFcSZXYKEWEU"}},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{"id":"3ytLXnTZbXLq"}},{"cell_type":"code","source":"def clean_text(text):\n    # Check for empty strings or non-string inputs\n    if not text or not isinstance(text, str):\n        return None\n\n    # Lowercase the text\n    text = text.lower()\n\n    # Remove words that contain numbers\n    text = re.sub(r'\\w*\\d\\w*', '', text)\n\n    # Preserve meaningful punctuation and numbers\n    text = re.sub(r\"[^a-z0-9.,!?;\\s']\", '', text)\n\n    # Remove words with characters other than letters in them\n    text = re.sub(r'\\s\\w*[.,!?;]\\w*\\s', ' ', text)\n\n    # Remove unnecessary whitespaces and handle line breaks\n    text = text.strip()\n    text = re.sub(r'\\s+', ' ', text)\n\n    # Remove repeating commas and periods\n    text = re.sub(r'[.]+', '.', text)\n    text = re.sub(r'[,]+', ',', text)\n    text = re.sub(r'\\.+[,]+', ',', text)\n    \n    if not is_valid_line(text):\n        return None\n    \n    return text\n\ndef is_valid_line(line):\n    if line and len(line) >= 2 and re.search('[a-z]', line):\n        return True\n    return False\n","metadata":{"id":"MvER1-0YZx3X","execution":{"iopub.status.busy":"2023-12-05T07:54:41.936820Z","iopub.execute_input":"2023-12-05T07:54:41.937184Z","iopub.status.idle":"2023-12-05T07:54:41.945619Z","shell.execute_reply.started":"2023-12-05T07:54:41.937153Z","shell.execute_reply":"2023-12-05T07:54:41.944725Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Tokenize","metadata":{"id":"kOdq1BRpwKXv"}},{"cell_type":"code","source":"import transformers\nfrom transformers import AutoTokenizer\n\n# For instance, using the BERT tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\nvocab_size = len(tokenizer)","metadata":{"id":"lCIyTscngptH","outputId":"221667fb-edff-46cb-9412-34e786e50413","execution":{"iopub.status.busy":"2023-12-05T07:54:41.947753Z","iopub.execute_input":"2023-12-05T07:54:41.948055Z","iopub.status.idle":"2023-12-05T07:54:42.753395Z","shell.execute_reply.started":"2023-12-05T07:54:41.948031Z","shell.execute_reply":"2023-12-05T07:54:42.752572Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ccfd47567c7465fbbe5c61ee58d3981"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ff45fc43c5e4e04b5c1a0d90eebe17d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59ec240add82412d9b4fa25b3f9201ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c75ca3c56e4843aa95bf29661e791765"}},"metadata":{}}]},{"cell_type":"code","source":"reddit_df = pd.read_csv('/kaggle/input/joke-csv/joke_csv')","metadata":{"execution":{"iopub.status.busy":"2023-12-05T07:58:58.796164Z","iopub.execute_input":"2023-12-05T07:58:58.796921Z","iopub.status.idle":"2023-12-05T07:58:59.341198Z","shell.execute_reply.started":"2023-12-05T07:58:58.796889Z","shell.execute_reply":"2023-12-05T07:58:59.340238Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"reddit_df.to_csv('joke.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T08:19:46.935170Z","iopub.execute_input":"2023-12-05T08:19:46.936157Z","iopub.status.idle":"2023-12-05T08:19:48.449842Z","shell.execute_reply.started":"2023-12-05T08:19:46.936110Z","shell.execute_reply":"2023-12-05T08:19:48.448931Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Calculate the length of each sequence in 'title' and 'body'\nreddit_df['title_length'] = reddit_df['title'].apply(len)\nreddit_df['body_length'] = reddit_df['body'].apply(len)\n\n# Combine the lengths to consider either 'title' or 'body'\nreddit_df['max_length'] = reddit_df[['title_length', 'body_length']].max(axis=1)\n\n# Determine the 90th percentile length\npercentile_90 = reddit_df['max_length'].quantile(0.95)\n\n# Filter out the top 10% longest sequences\nfiltered_df = reddit_df[reddit_df['max_length'] <= percentile_90]\n\n# Drop the additional columns if not needed\nfiltered_df = filtered_df.drop(columns=['title_length', 'body_length', 'max_length'])\n\nprint(\"Original dataframe size:\", len(reddit_df))\nprint(\"Filtered dataframe size:\", len(filtered_df))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T07:59:03.083321Z","iopub.execute_input":"2023-12-05T07:59:03.084297Z","iopub.status.idle":"2023-12-05T07:59:03.348499Z","shell.execute_reply.started":"2023-12-05T07:59:03.084265Z","shell.execute_reply":"2023-12-05T07:59:03.347401Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Original dataframe size: 189437\nFiltered dataframe size: 179981\n","output_type":"stream"}]},{"cell_type":"code","source":"reddit_df = filtered_df","metadata":{"execution":{"iopub.status.busy":"2023-12-05T07:59:03.350421Z","iopub.execute_input":"2023-12-05T07:59:03.351143Z","iopub.status.idle":"2023-12-05T07:59:03.359972Z","shell.execute_reply.started":"2023-12-05T07:59:03.351105Z","shell.execute_reply":"2023-12-05T07:59:03.358997Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"n = int(0.9*len(reddit_df))\ntrain_data = reddit_df[:n]\nval_data = reddit_df[n:]\n\nx_train, y_train = train_data['title'], train_data['body']\nx_val, y_val = val_data['title'], val_data['body']","metadata":{"execution":{"iopub.status.busy":"2023-12-05T07:59:03.361705Z","iopub.execute_input":"2023-12-05T07:59:03.362343Z","iopub.status.idle":"2023-12-05T07:59:03.373148Z","shell.execute_reply.started":"2023-12-05T07:59:03.362310Z","shell.execute_reply":"2023-12-05T07:59:03.372185Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"reddit_df","metadata":{"execution":{"iopub.status.busy":"2023-12-05T07:59:03.375209Z","iopub.execute_input":"2023-12-05T07:59:03.375480Z","iopub.status.idle":"2023-12-05T07:59:03.392169Z","shell.execute_reply.started":"2023-12-05T07:59:03.375457Z","shell.execute_reply":"2023-12-05T07:59:03.391212Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"                                                     body  \\\n0       now i have to say leroy can you please paint t...   \n1       pizza doesn't scream when you put it in the ov...   \n2       .and being there really helped me learn about ...   \n3       a sunday school teacher is concerned that his ...   \n4       he got caught trying to sell the two books to ...   \n...                                                   ...   \n189432  gives me something to read while i'm in the sh...   \n189433                            i mean dyslexia fcuk!!!   \n189434       a hockey player showers after three periods.   \n189435  a father buys a lie detector robot that slaps ...   \n189436                                it was a 'shih tzu'   \n\n                                                    title  \n0        i hate how you cant even say black paint anymore  \n1       what's the difference between a jew in nazi ge...  \n2                             i recently went to america.  \n3                brian raises his hand and hes in heaven.  \n4       you hear about the university book store worke...  \n...                                                   ...  \n189432     i like a girl with words tattooed on her back.  \n189433                                   i have sexdaily.  \n189434  what's the difference between a hippie chick a...  \n189435                                   new family robot  \n189436     i went to a zoo and there was only one animal.  \n\n[179981 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>body</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>now i have to say leroy can you please paint t...</td>\n      <td>i hate how you cant even say black paint anymore</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>pizza doesn't scream when you put it in the ov...</td>\n      <td>what's the difference between a jew in nazi ge...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>.and being there really helped me learn about ...</td>\n      <td>i recently went to america.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a sunday school teacher is concerned that his ...</td>\n      <td>brian raises his hand and hes in heaven.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>he got caught trying to sell the two books to ...</td>\n      <td>you hear about the university book store worke...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>189432</th>\n      <td>gives me something to read while i'm in the sh...</td>\n      <td>i like a girl with words tattooed on her back.</td>\n    </tr>\n    <tr>\n      <th>189433</th>\n      <td>i mean dyslexia fcuk!!!</td>\n      <td>i have sexdaily.</td>\n    </tr>\n    <tr>\n      <th>189434</th>\n      <td>a hockey player showers after three periods.</td>\n      <td>what's the difference between a hippie chick a...</td>\n    </tr>\n    <tr>\n      <th>189435</th>\n      <td>a father buys a lie detector robot that slaps ...</td>\n      <td>new family robot</td>\n    </tr>\n    <tr>\n      <th>189436</th>\n      <td>it was a 'shih tzu'</td>\n      <td>i went to a zoo and there was only one animal.</td>\n    </tr>\n  </tbody>\n</table>\n<p>179981 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"_j91TWgg2aM-"}},{"cell_type":"code","source":"# single head\nclass Head(nn.Module):\n\n  def __init__(self, head_size):\n    super().__init__()\n    self.key = nn.Linear(n_embd, head_size, bias=False)\n    self.query = nn.Linear(n_embd, head_size, bias=False)\n    self.value = nn.Linear(n_embd, head_size, bias=False)\n    self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n\n    self.dropout = nn.Dropout(dropout)\n\n  def forward(self, x, mask=None):\n    B,T,C = x.shape\n    k = self.key(x)\n    q = self.query(x)\n        \n    wei = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5\n    \n    # mask\n    if mask is not None:\n        wei = wei.masked_fill(mask.unsqueeze(1) == 0, float('-inf'))\n    else:\n        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n        \n    wei = F.softmax(wei, dim=-1)\n    wei = self.dropout(wei)\n\n    v = self.value(x)\n    out = wei @ v\n    return out\n\n# multi-head\nclass MultiHeadAttention(nn.Module):\n\n  def __init__(self, num_heads, head_size):\n    super().__init__()\n    \n    # mask\n    self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n    self.proj = nn.Linear(n_embd, n_embd)\n    self.dropout = nn.Dropout(dropout)\n    \n  def forward(self, x, mask=None):\n    # mask\n    if mask is not None:\n        out = torch.cat([h(x, mask) for h in self.heads], dim=-1)\n    else:\n        out = torch.cat([h(x) for h in self.heads], dim=-1)\n    out = self.dropout(self.proj(out))\n    return out\n\nclass FeedForward(nn.Module):\n\n  def __init__(self, n_embd):\n    super().__init__()\n    self.net = nn.Sequential(\n        nn.Linear(n_embd, 4 * n_embd),\n        nn.ReLU(),\n        nn.Linear(4 * n_embd, n_embd),\n        nn.Dropout(dropout),\n    )\n\n  def forward(self, x):\n    return self.net(x)\n\nclass Block(nn.Module):\n\n  def __init__(self, n_embd, n_head):\n    super().__init__()\n    head_size = n_embd // n_head\n    \n    self.sa = MultiHeadAttention(n_head, head_size)\n    self.ffwd = FeedForward(n_embd)\n    self.ln1 = nn.LayerNorm(n_embd)\n    self.ln2 = nn.LayerNorm(n_embd)\n\n  def forward(self, x, mask=None):\n    x = x + self.sa(self.ln1(x), mask) # if mask is not None else x + self.sa(self.ln1(x))\n    x = x + self.ffwd(self.ln2(x))\n    return x","metadata":{"id":"0nArmzUyTxLo","execution":{"iopub.status.busy":"2023-12-05T07:59:03.393472Z","iopub.execute_input":"2023-12-05T07:59:03.393778Z","iopub.status.idle":"2023-12-05T07:59:03.412714Z","shell.execute_reply.started":"2023-12-05T07:59:03.393752Z","shell.execute_reply":"2023-12-05T07:59:03.411730Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"class GPTLanguageModel(nn.Module):\n  def __init__(self):\n    super().__init__()\n    self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n    self.position_embedding_table = nn.Embedding(block_size, n_embd)\n    self.blocks = nn.ModuleList([Block(n_embd, n_head=n_head) for _ in range(n_layer)]) \n    self.ln_f = nn.LayerNorm(n_embd)\n    self.ln_f = nn.LayerNorm(n_embd)\n    self.lm_head = nn.Linear(n_embd, vocab_size)\n\n  def forward(self, idx, targets=None, mask=None):\n    B, T = idx.shape\n\n    tok_emb = self.token_embedding_table(idx)\n    pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n    x = tok_emb + pos_emb\n\n    for block in self.blocks:\n        x = block(x, mask) if mask is not None else block(x)\n                    \n    x = self.ln_f(x)\n    logits = self.lm_head(x)\n\n    if targets is None:\n        loss = None\n    else:\n        B, T, C = logits.shape\n        logits = logits.view(B*T, C)\n        targets = targets.view(B*T)\n        loss = F.cross_entropy(logits, targets)\n\n    return logits, loss\n\n  def generate(self, idx, max_new_tokens):\n\n    for _ in range(max_new_tokens):\n        idx_cond = idx[:, -block_size:]\n        logits, loss = self.forward(idx_cond)\n        logits = logits[:, -1, :]\n        probs = F.softmax(logits, dim=-1)\n        idx_next = torch.multinomial(probs, num_samples=1)\n        idx = torch.cat((idx, idx_next), dim=1)\n    return idx\n","metadata":{"id":"PPPcEOQCT0e3","execution":{"iopub.status.busy":"2023-12-05T07:59:03.413873Z","iopub.execute_input":"2023-12-05T07:59:03.414181Z","iopub.status.idle":"2023-12-05T07:59:03.427629Z","shell.execute_reply.started":"2023-12-05T07:59:03.414156Z","shell.execute_reply":"2023-12-05T07:59:03.426737Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"# Batches","metadata":{"id":"yud7dRn84n7v"}},{"cell_type":"code","source":"def find_max_length(list_of_texts):\n    return max(len(tokenizer.encode(text, add_special_tokens=False)) for text in list_of_texts)\n\ndef encode_and_pad(texts, max_length):\n    encoded_dict = tokenizer.batch_encode_plus(\n        texts,\n        max_length=max_length,\n        padding='max_length',\n        truncation=True,\n        return_tensors='pt',\n        add_special_tokens=True\n    )\n\n    input_ids = encoded_dict['input_ids']\n    attention_masks = encoded_dict['attention_mask']\n\n    return input_ids, attention_masks\n\ndef get_batch(split): \n    data = train_data if split == 'train' else val_data\n\n    start_idx = current_index[split]\n    end_idx = start_idx + batch_size\n\n    batch_data = data[start_idx:end_idx]\n\n    current_index[split] = end_idx % len(data)  # Loop back to start if we reach the end\n\n    x = batch_data['title']\n    y = batch_data['body']\n\n    max_length = max(find_max_length(x), find_max_length(y))\n    x, x_mask = encode_and_pad(list(x), max_length)\n    y, _ = encode_and_pad(list(y), max_length)\n    \n    if x.size(1) > block_size:\n        x = x[:, :block_size]\n    if y.size(1) > block_size:\n        y = y[:, :block_size]\n    if x_mask.size(1) > block_size:\n        x_mask = x_mask[:, :block_size]\n    \n    x, y, x_mask = x.to(device), y.to(device), x_mask.to(device)\n\n    return x, y, x_mask\n\ndef decode(data):\n\n    if torch.is_tensor(data):\n        data = data.tolist()\n\n    if isinstance(data[0], list) or isinstance(data[0], torch.Tensor):\n        decoded_strings = [tokenizer.decode(seq, skip_special_tokens=True) for seq in data]\n    else:\n        # Single sequence\n        decoded_strings = tokenizer.decode(data, skip_special_tokens=True)\n\n    return decoded_strings","metadata":{"execution":{"iopub.status.busy":"2023-12-05T07:59:03.428768Z","iopub.execute_input":"2023-12-05T07:59:03.429043Z","iopub.status.idle":"2023-12-05T07:59:03.443566Z","shell.execute_reply.started":"2023-12-05T07:59:03.429020Z","shell.execute_reply":"2023-12-05T07:59:03.442699Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef estimate_loss():\n  out = {}\n  model.eval()\n  model.to(device)\n  losses = torch.zeros(100)\n  for split in ['train', 'val']:\n    for k in range(100):\n      X, Y, x_mask = get_batch(split)\n      X, Y, x_mask = X.to(device), Y.to(device), x_mask.to(device)\n      logits, loss = model(X, Y, x_mask)\n      losses[k] = loss.item()\n    out[split] = losses.mean()\n  model.train()\n  return out","metadata":{"id":"_Ih_QZE5fcxT","execution":{"iopub.status.busy":"2023-12-05T07:59:03.444826Z","iopub.execute_input":"2023-12-05T07:59:03.445111Z","iopub.status.idle":"2023-12-05T07:59:03.457648Z","shell.execute_reply.started":"2023-12-05T07:59:03.445062Z","shell.execute_reply":"2023-12-05T07:59:03.456893Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"id":"pxhDFqrebzep"}},{"cell_type":"markdown","source":"## Hyperparameters","metadata":{"id":"CSV1U1wxl4Bq"}},{"cell_type":"code","source":"# hyperparameters\nbatch_size = 50\nblock_size = 128\nmax_iters = 1000\neval_interval = 100\nlearning_rate = 1e-4\neval_iters = 1000\nn_embd = 200\nn_head = 8\nn_layer = 8\ndropout = 0.2\n#device = torch.device(\"cuda\")\n#vocab_size = len(chars)\n\nhyperparameters = {\n    'batch_size': batch_size,\n    'block_size': block_size,\n    'max_iters': max_iters,\n    'eval_interval': eval_interval,\n    'learning_rate': learning_rate,\n    'eval_iters': eval_iters,\n    'n_embd': n_embd,\n    'n_head': n_head,\n    'n_layer': n_layer,\n    'dropout': dropout,\n}\n\n# Hyperparameter -> Loss Visualization Data\n# Essentially for every run, record the hyperparams and\n# Plot them compared to old (save old in file)\nvis_data = {\n    'batch_size': batch_size,\n    'block_size': block_size,\n    'max_iters': max_iters,\n    'eval_interval': eval_interval,\n    'learning_rate': learning_rate,\n    'eval_iters': eval_iters,\n    'n_embd': n_embd,\n    'n_head': n_head,\n    'n_layer': n_layer,\n    'dropout': dropout,\n}\n\nvis_data_file_name = \"visual_data_during_training.txt\"\nvis_post_data_file_name = \"visual_data_post_training.txt\"","metadata":{"id":"O95QHgGUT_4n","execution":{"iopub.status.busy":"2023-12-05T08:14:02.830508Z","iopub.execute_input":"2023-12-05T08:14:02.831628Z","iopub.status.idle":"2023-12-05T08:14:02.840032Z","shell.execute_reply.started":"2023-12-05T08:14:02.831584Z","shell.execute_reply":"2023-12-05T08:14:02.839099Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"# model\nmodel = GPTLanguageModel()\nmodel.to(device)\nprint(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n\n# Visualization Data\nvis_data_iterations = [] # Format: [[iteration, train_loss, val_loss]]\n\n# optimizer\noptimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)","metadata":{"id":"_3az1gNpUe8B","outputId":"f931a037-b4e5-4e6d-ffdc-027ce388fd0d","execution":{"iopub.status.busy":"2023-12-05T07:59:03.482874Z","iopub.execute_input":"2023-12-05T07:59:03.483180Z","iopub.status.idle":"2023-12-05T07:59:03.687402Z","shell.execute_reply.started":"2023-12-05T07:59:03.483152Z","shell.execute_reply":"2023-12-05T07:59:03.686484Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"16.121322 M parameters\n","output_type":"stream"}]},{"cell_type":"code","source":"base_model_128_4_4_path = '/content/drive/MyDrive/Project/Saved model/model_128_4_4.pth'\nbase_model_128_8_8_path =  '/content/drive/MyDrive/Project/Saved model/base_model_128_8_8.pth'\n\nfine_tuned_model_128_4_4_path = '/content/drive/MyDrive/Project/Saved model/fine_tuned_model_128_4_4.pth'\nbase_model_200_4_4_path = '/content/drive/MyDrive/Project/Saved model/base_model_200_4_4.pth'\n\nbase_model_200_8_8_wordlevel = '/kaggle/input/base-model-word-level/base_model_200_8_8_wordlevel_1.pth'\nfine_tuned_model_200_8_8_word_level_path = '/kaggle/working/fine_tuned_model_200_8_8_word_level.pth'","metadata":{"id":"CkYeFfxe3xaI","execution":{"iopub.status.busy":"2023-12-05T08:17:19.153840Z","iopub.execute_input":"2023-12-05T08:17:19.154253Z","iopub.status.idle":"2023-12-05T08:17:19.159709Z","shell.execute_reply.started":"2023-12-05T08:17:19.154220Z","shell.execute_reply":"2023-12-05T08:17:19.158484Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"path = fine_tuned_model_200_8_8_word_level_path\ncheckpoint = torch.load(path)\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])","metadata":{"execution":{"iopub.status.busy":"2023-12-05T08:17:21.029722Z","iopub.execute_input":"2023-12-05T08:17:21.030120Z","iopub.status.idle":"2023-12-05T08:17:21.366657Z","shell.execute_reply.started":"2023-12-05T08:17:21.030092Z","shell.execute_reply":"2023-12-05T08:17:21.365774Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"current_index = {'train':0, 'val':0}\nglobal current_index","metadata":{"execution":{"iopub.status.busy":"2023-12-05T07:59:04.016806Z","iopub.execute_input":"2023-12-05T07:59:04.017483Z","iopub.status.idle":"2023-12-05T07:59:04.022162Z","shell.execute_reply.started":"2023-12-05T07:59:04.017448Z","shell.execute_reply":"2023-12-05T07:59:04.021107Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"current_index","metadata":{"execution":{"iopub.status.busy":"2023-12-05T08:17:24.592894Z","iopub.execute_input":"2023-12-05T08:17:24.593676Z","iopub.status.idle":"2023-12-05T08:17:24.599640Z","shell.execute_reply.started":"2023-12-05T08:17:24.593638Z","shell.execute_reply":"2023-12-05T08:17:24.598676Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"{'train': 68468, 'val': 15456}"},"metadata":{}}]},{"cell_type":"code","source":"fabric.launch()\n\nexperiment = Experiment(\n  api_key=\"78u2AfbhkXeTChB3Kzb7FhOEY\",\n  project_name=\"JokeGPT\",\n  workspace=\"lzh0212\"\n)\n\nexperiment.log_parameters(hyperparameters)\nfor iter in range(1000):\n\n    xb, yb, x_mask = get_batch('train')\n    logits, loss = model(xb, yb, x_mask)\n\n    if iter % eval_interval == 0 or iter == max_iters - 1:\n        losses = estimate_loss()\n        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n        experiment.log_metric('train loss', losses['train'], step=iter)\n        experiment.log_metric('val loss', losses['val'], step=iter)\n\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()\n\nexperiment.end()","metadata":{"id":"rRuissSBawv5","execution":{"iopub.status.busy":"2023-12-05T08:17:32.021613Z","iopub.execute_input":"2023-12-05T08:17:32.021979Z","iopub.status.idle":"2023-12-05T08:18:21.666853Z","shell.execute_reply.started":"2023-12-05T08:17:32.021951Z","shell.execute_reply":"2023-12-05T08:18:21.665254Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stderr","text":"\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/lzh0212/jokegpt/fc250b1f161248b796c2617df25bf3dc\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [40]      : (0.8195207118988037, 2.3504509925842285)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train loss [4] : (1.2682777643203735, 1.494596242904663)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     val loss [4]   : (1.9718263149261475, 2.183565378189087)\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     batch_size    : 50\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     block_size    : 128\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dropout       : 0.2\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_interval : 100\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_iters    : 1000\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     learning_rate : 0.0001\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_iters     : 1000\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     n_embd        : 200\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     n_head        : 8\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     n_layer       : 8\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-environment-definition : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-info                   : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-specification          : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details          : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                     : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages           : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                     : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages                  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code                  : 1\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/lzh0212/jokegpt/5f9268b305634b2596338f69855992fb\n\n","output_type":"stream"},{"name":"stdout","text":"step 0: train loss 1.4322, val loss 1.9986\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[75], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m model(xb, yb, x_mask)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m%\u001b[39m eval_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m==\u001b[39m max_iters \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 16\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28miter\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: train loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m     experiment\u001b[38;5;241m.\u001b[39mlog_metric(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain loss\u001b[39m\u001b[38;5;124m'\u001b[39m, losses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m], step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28miter\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[48], line 9\u001b[0m, in \u001b[0;36mestimate_loss\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      8\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m     X, Y, x_mask \u001b[38;5;241m=\u001b[39m \u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     X, Y, x_mask \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), Y\u001b[38;5;241m.\u001b[39mto(device), x_mask\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m     logits, loss \u001b[38;5;241m=\u001b[39m model(X, Y, x_mask)\n","Cell \u001b[0;32mIn[47], line 34\u001b[0m, in \u001b[0;36mget_batch\u001b[0;34m(split)\u001b[0m\n\u001b[1;32m     32\u001b[0m max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(find_max_length(x), find_max_length(y))\n\u001b[1;32m     33\u001b[0m x, x_mask \u001b[38;5;241m=\u001b[39m encode_and_pad(\u001b[38;5;28mlist\u001b[39m(x), max_length)\n\u001b[0;32m---> 34\u001b[0m y, _ \u001b[38;5;241m=\u001b[39m \u001b[43mencode_and_pad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m block_size:\n\u001b[1;32m     37\u001b[0m     x \u001b[38;5;241m=\u001b[39m x[:, :block_size]\n","Cell \u001b[0;32mIn[47], line 5\u001b[0m, in \u001b[0;36mencode_and_pad\u001b[0;34m(texts, max_length)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_and_pad\u001b[39m(texts, max_length):\n\u001b[0;32m----> 5\u001b[0m     encoded_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m encoded_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     15\u001b[0m     attention_masks \u001b[38;5;241m=\u001b[39m encoded_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3075\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3065\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3066\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3067\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3068\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3072\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3073\u001b[0m )\n\u001b[0;32m-> 3075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3077\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3092\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3093\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:552\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_ids \u001b[38;5;129;01min\u001b[39;00m sanitized_tokens[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eventual_warn_about_too_long_sequence(input_ids, max_length, verbose)\n\u001b[0;32m--> 552\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msanitized_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitized_encodings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:223\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    219\u001b[0m     n_sequences \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_sequences\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_sequences \u001b[38;5;241m=\u001b[39m n_sequences\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:748\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    745\u001b[0m     value \u001b[38;5;241m=\u001b[39m [value]\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> 748\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m tensor\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:720\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors.<locals>.as_tensor\u001b[0;34m(value, dtype)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value[\u001b[38;5;241m0\u001b[39m], np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray(value))\n\u001b[0;32m--> 720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"},{"name":"stderr","text":"\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Error exporting current conda environment\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Save the model","metadata":{"id":"NXMA91bMF9Un"}},{"cell_type":"code","source":"def save(model, optimizer, hyperparameters, base_path='/kaggle/working/'):\n    n_embd = hyperparameters['n_embd']\n    n_head = hyperparameters['n_head']\n    n_layer = hyperparameters['n_layer']\n\n    filename = f\"fine_tuned_model_{n_embd}_{n_head}_{n_layer}_word_level.pth\"\n    full_path = base_path + filename\n\n    torch.save({\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'hyperparameters': hyperparameters\n    }, full_path)\n\n    print(f\"Checkpoint saved to {full_path}\")","metadata":{"id":"opVU4Xin0-eK","execution":{"iopub.status.busy":"2023-12-05T08:08:47.958504Z","iopub.execute_input":"2023-12-05T08:08:47.959345Z","iopub.status.idle":"2023-12-05T08:08:47.965495Z","shell.execute_reply.started":"2023-12-05T08:08:47.959312Z","shell.execute_reply":"2023-12-05T08:08:47.964508Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"save(model, optimizer, hyperparameters)","metadata":{"id":"Bq0Wh7kJndCF","execution":{"iopub.status.busy":"2023-12-05T08:08:50.602806Z","iopub.execute_input":"2023-12-05T08:08:50.603450Z","iopub.status.idle":"2023-12-05T08:08:51.352555Z","shell.execute_reply.started":"2023-12-05T08:08:50.603421Z","shell.execute_reply":"2023-12-05T08:08:51.351586Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Checkpoint saved to /kaggle/working/fine_tuned_model_200_8_8_word_level.pth\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Result","metadata":{"id":"-Ki9UU6A2d1A"}},{"cell_type":"code","source":"base_model_128_4_4_path = '/content/drive/MyDrive/Project/Saved model/model_128_4_4.pth'\nfined_tuned_model_128_4_4_path = '/content/drive/MyDrive/Project/Saved model/fine_tuned_model_128_4_4.pth'\nfined_tuned_model_200_8_8_path = '/content/drive/MyDrive/Project/Saved model/model_200_8_8.pth'","metadata":{"id":"k1b-r0YhCIjq","execution":{"iopub.status.busy":"2023-12-05T08:05:24.554402Z","iopub.execute_input":"2023-12-05T08:05:24.554661Z","iopub.status.idle":"2023-12-05T08:05:24.559116Z","shell.execute_reply.started":"2023-12-05T08:05:24.554638Z","shell.execute_reply":"2023-12-05T08:05:24.558134Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# model = GPTLanguageModel()\n# model.to(device)\n\n# path = fined_tuned_model_128_4_4_path\n# checkpoint = torch.load(path)\n# model.load_state_dict(checkpoint['model_state_dict'])","metadata":{"id":"wN8Gl1TmB9Y8","execution":{"iopub.status.busy":"2023-12-05T08:05:24.560200Z","iopub.execute_input":"2023-12-05T08:05:24.560473Z","iopub.status.idle":"2023-12-05T08:05:24.570486Z","shell.execute_reply.started":"2023-12-05T08:05:24.560448Z","shell.execute_reply":"2023-12-05T08:05:24.569594Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"prompt = 'hello'\ncontext = torch.tensor(tokenizer.encode(prompt), dtype=torch.long, device=device)\ngenerated_chars = decode(model.generate(context.unsqueeze(0), max_new_tokens=100)[0].tolist())\nprint(generated_chars)","metadata":{"id":"k6kfXKbWD1V4","execution":{"iopub.status.busy":"2023-12-05T08:05:24.571569Z","iopub.execute_input":"2023-12-05T08:05:24.571839Z","iopub.status.idle":"2023-12-05T08:05:37.510621Z","shell.execute_reply.started":"2023-12-05T08:05:24.571815Z","shell.execute_reply":"2023-12-05T08:05:37.509624Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"hello where johnmy may cops are no audience french that the in of joke and so fracture an histe hours you bar ice that when will was he touch. her s room what teacher saw the and asks the take it was sees\n","output_type":"stream"}]},{"cell_type":"code","source":"context = torch.zeros((1, 1), dtype=torch.long, device=device)\nprint(decode(model.generate(context, max_new_tokens=500)[0].tolist()))","metadata":{"id":"JqYBg_SfNJa3","execution":{"iopub.status.busy":"2023-12-05T08:20:55.340193Z","iopub.execute_input":"2023-12-05T08:20:55.340613Z","iopub.status.idle":"2023-12-05T08:21:09.069099Z","shell.execute_reply.started":"2023-12-05T08:20:55.340580Z","shell.execute_reply":"2023-12-05T08:21:09.068122Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"declares inside a a in. once stop i will not i turned coffee one i was to the room people i and it corn before i of later just she the checked'rabbit turns they the chief for also the'is live would of or tony the the it about so to and. memen\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"u6xZuBLVPXrm"},"execution_count":null,"outputs":[]}]}